{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão de Inadimplência - Random Forest (Base UCI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configuração Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, confusion_matrix, \n",
    "                            ConfusionMatrixDisplay, RocCurveDisplay)\n",
    "from scipy.stats import randint, uniform\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Configurações\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"default_of_credit_card_clients.xls\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
    "    urlretrieve(url, file_path)\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_excel(file_path, header=1)\n",
    "df = df.rename(columns={'default payment next month': 'DEFAULT'})\n",
    "\n",
    "# Preparar features e target\n",
    "features = [col for col in df.columns if col not in ['ID', 'DEFAULT']]\n",
    "X = df[features]\n",
    "y = df['DEFAULT']\n",
    "\n",
    "# Dividir dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelagem - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "# Criar modelo base\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Espaço de parâmetros para busca aleatória\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': [None] + list(np.arange(5, 30, 5)),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# Busca aleatória\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_dist, n_iter=50, cv=5, scoring='roc_auc',\n",
    "    n_jobs=-1, random_state=42, verbose=1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhor modelo\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Métricas\n",
    "metrics = {\n",
    "    'model': 'random_forest',\n",
    "    'best_params': random_search.best_params_,\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'precision': precision_score(y_test, y_pred),\n",
    "    'recall': recall_score(y_test, y_pred),\n",
    "    'f1_score': f1_score(y_test, y_pred),\n",
    "    'roc_auc': roc_auc_score(y_test, y_proba),\n",
    "    'features': features\n",
    "}\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"Melhores parâmetros:\", random_search.best_params_)\n",
    "print(\"\\nMétricas de avaliação:\")\n",
    "for k, v in metrics.items():\n",
    "    if k not in ['model', 'best_params', 'features']:\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Visualizações\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax1)\n",
    "ax1.set_title('Matriz de Confusão')\n",
    "\n",
    "# Curva ROC\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test, ax=ax2)\n",
    "ax2.set_title('Curva ROC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Importância das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair importância das features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plotar as 15 mais importantes\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n",
    "plt.title('Top 15 Features Mais Importantes')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salvamento do Modelo e Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelo\n",
    "joblib.dump(best_model, '../models/random_forest_model.pkl')\n",
    "\n",
    "# Carregar métricas existentes e adicionar novas\n",
    "try:\n",
    "    with open('../models/model_metrics.json', 'r') as f:\n",
    "        all_metrics = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    all_metrics = []\n",
    "\n",
    "all_metrics.append(metrics)\n",
    "\n",
    "with open('../models/model_metrics.json', 'w') as f:\n",
    "    json.dump(all_metrics, f)\n",
    "\n",
    "print(\"Modelo e métricas atualizados com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
